
# A strategy for successfully building applications using Hibernate and jOOQ

Building performant and maintainable applications using [Hibernate ORM](https://hibernate.org/orm/)
can be hard. At least that has been my experience for a long time. To be honest, I did not understand
Hibernate sufficiently well, and neither did many of my co-workers.

Moreover, I considered Hibernate as being more or less synonymous with the first-level cache, not realizing
that *JPQL* (as an "object-oriented SQL dialect") might be more fundamental. I also had no idea that
Hibernate offered a `StatelessSession` (without first-level cache) as alternative to `Session`
(which extends JPA interface `EntityManager`).

At some point, with the help of resources such as
[A Short Guide to Hibernate](https://docs.hibernate.org/orm/7.1/introduction/html_single/) and lots
of experimentation I started to "get" Hibernate. The general idea is *working with the database rather
than against it*. Too often I have seen attempts to "abstract away" the database using Hibernate (or
other ORMs), which is counterproductive, leading to non-performant, brittle, hard to maintain code. In
such code bases it is extremely hard to predict which SQL statements are generated by Hibernate (without
the help of Hibernate logging).

That said, Hibernate/JPA *entities* are quite poor *data transfer objects* for passing around across
application layers. Their mutability and use of proxy objects is a strength within an open
JPA `EntityManager` (or Hibernate `Session`), but a liability when passing around "data objects"
through the application (from service layer to web layer, for example).

A successful strategy for using Hibernate could therefore be as follows:
* Within an open JPA `EntityManager`, use Hibernate to work *with the database* as much as possible
  * See good resources on effective use of Hibernate in order to be successful
* Outside the `EntityManager`/`Session`, pass around data as *deeply immutable Java record class instances*
  * See for example the book *Effective Java, 3rd Edition*, by Joshua Bloch, on *minimizing mutability*

The underlying paradigms involved are quite different:
* Within an open `EntityManager`: JPA entities as old-school mutable JavaBeans, using `null` everywhere, and with lots of hidden state
* Outside the `EntityManager`: immutable Java records, avoiding `null` but using (type-safe) `Optional` instead, and without any hidden state

Sometimes Hibernate is not a good fit, and directly working with SQL in a type-safe manner is preferable.
This is where [jOOQ](https://www.jooq.org/) shines. Combining jOOQ and Hibernate in the same code base
is quite normal, and works very well with technology-agnostic service interfaces working with immutable
data objects.

In this and other projects I explore these ideas. Combining seemingly conflicting ideas in the same
code base can be made bearable by the use of clear Javadoc comments in `package-info.java` source files.

## Using Hibernate (as JPA implementation) in tandem with the database

Some general advice on using Hibernate ORM, from the horse's mouth, can be found
[here](https://docs.hibernate.org/orm/7.1/introduction/html_single/#advice). The most common problem
with Hibernate is causing the creation and execution of too many SQL queries, in particular due to the
*N + 1 selects* problem
(see [Association Fetching](https://docs.hibernate.org/orm/7.1/introduction/html_single/#association-fetching)).

This is easy to avoid when writing SQL ourselves, which is what we do when using *low-level JDBC* or
the Spring `JdbcTemplate` (which at least takes JDBC resource and transaction management out of our hands).
With Hibernate we have to know not just SQL, but also the abstraction that Hibernate offers.

As said before, we should work in tandem with the database. When writing SQL ourselves, we are used
to *joining tables on an ad-hoc basis*. We could mimic this idea when using Hibernate too.
That is, consider *JPA entities* as *Java representations of database table rows*, choosing *lazy
fetching* for *all associations*. Per JPQL or Criteria query, an `EntityGraph` or `FETCH JOIN`'s could be used on
an *ad-hoc* basis, to make explicit which associations should be fetched.

The [Tutorials by Thorben Janssen](https://thorben-janssen.com/tutorials/) site can to a large extent be considered
a one-stop shop for "all things Hibernate/JPA". It comes with great advice about how to use Hibernate
effectively. For example, the advice about using lazy fetching can be found
[here](https://thorben-janssen.com/hibernate-performance-tuning/). In particular:
[Use Lazy Fetching](https://thorben-janssen.com/hibernate-performance-tuning/#avoid-unnecessary-queries--choose-the-right-fetchtype)
and [Use Query-specific Fetching](https://thorben-janssen.com/hibernate-performance-tuning/#avoid-unnecessary-queries--use-queryspecific-fetching).

Note that *consistently using lazy fetching for entity associations* vastly increases *maintainability* of the
code base, because "association fetching concerns" are *localized* to pieces of code dealing with one specific
JPQL/Criteria query. This is also the reason I do not believe in "generic DAO code" offering generic
JPA method calls.

So far I haven't really seen that advice being followed in practice. Hence, my prior misconception that Hibernate is
intrinsically very hard to use well.

Also see the other Hibernate performance advice in
[here](https://thorben-janssen.com/hibernate-performance-tuning/). More on Hibernate performance can be
found in [Hibernate Performance](https://thorben-janssen.com/tutorials/#performance).

Sometimes it can be a bit hard to choose between alternative solutions to a problem if these alternatives
each have their downsides. For example,
[Many-to-Many Association Collections](https://thorben-janssen.com/5-common-hibernate-mistakes-that-cause-dozens-of-unexpected-queries/#4-modeling-manytomany-associations-as-a-list)
suggests we should use `java.util.Set` rather than `java.util.List` for many-to-many associations. Yet that
requires high quality `equals` and `hashCode` methods to be implemented for the association element type,
although that is not mentioned in this advice. Defining stable `equals`/`hashCode` for mutable JPA entities
is a challenge in itself. Basing it on the technical primary key is a bad idea if the primary key is
generated by the database. If we don't additionally have a good "natural key" to base `equals` on it
becomes quite hard to override `equals`/`hashCode` without violating their "contracts" as defined in
the Javadoc documentation of class `java.lang.Object`. If needed, we can split a JPQL/Criteria query into 2
queries, combining the results afterward. This can also be a valid choice when faced with Hibernate's
[`MultipleBagFetchException`](https://thorben-janssen.com/fix-multiplebagfetchexception-hibernate/).

One Hibernate feature I try not to lean on too much is *dirty checking*. See e.g.
[persist, save, merge or update](https://thorben-janssen.com/persist-save-merge-saveorupdate-whats-difference-one-use/),
in particular
[updating a managed entity](https://thorben-janssen.com/persist-save-merge-saveorupdate-whats-difference-one-use/#updating-a-managed-entity),
or [Hibernate dirty check](https://www.baeldung.com/java-hibernate-entity-dirty-check).
After all, *dirty checking* is the epitome of *mutability*, to the point that setting a field of a
managed entity "automagically" leads to a database update. Convenient as this may sound, it does
hide the SQL generated by Hibernate.

As mentioned [here](https://docs.hibernate.org/orm/7.1/introduction/html_single/#advice), keep things
simple, and take control over generated SQL. Partly repeating myself, to me this means:
* Use *lazy fetching* for all entity associations
* Use *query-specific fetching*, thus also avoiding Hibernate's [`LazyInitializationException`](https://thorben-janssen.com/lazyinitializationexception/)
* Avoid overusing *cascading* of operations

In a large code base maintained by multiple developers we can stimulate the use of these best practices
as follows:
* Clearly documenting these *design considerations* in `package-info.java` source files (at application layer boundaries)
* At the same time, *validating* the code base against these best practices with [ArchUnit](https://www.archunit.org/)

Finally, *Java is statically typed*, which makes Java feel "a bit heavy" to some, but at least makes
maintaining and refactoring a Java code base practical. With Hibernate we easily lose some of that type-safety,
unless we use its [Static Metamodel Generator](https://docs.hibernate.org/orm/7.2/userguide/html_single/#tooling-modelgen)
as well as [Criteria Queries](https://docs.hibernate.org/orm/7.2/userguide/html_single/#criteria)
rather than plain [HQL/JPQL](https://docs.hibernate.org/orm/7.2/userguide/html_single/#hql). In my view,
this helps find many small programming errors as early as possible, which is a good thing.

## Using service interfaces, and passing data around as immutable Java records

Typically, large Java web applications have a *service layer* that hides database access details and other
service implementation details from higher layers using the service layer, such as the "web layer".

In particular at the service layer boundary it makes sense to use *Java interfaces* without any implementation
code as *purely abstract service layer API*. Preferably this API is completely technology-agnostic. That
would also mean it should not take or return JPA entities in its service methods. More about that follows
below.

With a service layer contract as Java interface it becomes quite natural to mock the service layer in
unit tests of higher layer code (such as code in the "web layer"). Mocking concrete service implementations feels
like a hack, whereas mocking service interfaces clearly does not.

Yet what kind of "data classes" should service methods (take and) return? Besides being bound to
technology (namely, JPA) *JPA entities* are quite poor *data transfer objects*. Recall Joshua Bloch's
*Effective Java, 3rd Edition*, and the item on *minimizing mutability*. As Joshua Bloch clearly shows,
immutability or at least minimizing mutability makes *reasoning about code* much easier, leading to
far fewer bugs. This advice also applies to "data classes". Let's see how *JPA entities* do in this
regard:
* they are highly mutable, so harder to reason about (w.r.t. their "state space")
* they typically allow for `null` to be used for all fields
* they depend on *hidden state*, such as:
  * the presence or absence of a `Session` ("persistence context")
  * the *lifecycle state* of the entity (if there is a "persistence context")
  * the extent to which *associations* have been loaded
  * cascading behavior, etc.
* related to the previous bullet point: they contain *annotations* and therefore *depend on annotation processing* external to the entity
* they can lead to the dreaded [`LazyInitializationException`](https://thorben-janssen.com/lazyinitializationexception/) (if there is no "persistence context")
* they make use of [Hibernate proxies](https://thorben-janssen.com/hibernate-proxies/), thus hiding the real JPA entity
* they certainly are not thread-safe, although sometimes that would be a desirable property
* they are not technology-agnostic
* they support bidirectional associations, which has its pros and cons
* in practice, they often tend to "attract" the use of legacy APIs such as the mutable `java.util.Date`
* defining *equality* (through overriding of `equals` and `hashCode`) can be a challenge for these mutable data structures
* this programming style is rooted in old-school *imperative Java programming*, characterized by "mutability and side effects everywhere"

In my opinion it is well worth the effort to keep JPA entities local to "database access code",
and convert them to *(deeply) immutable Java records* (as "immutable DTOs" or "immutable value objects").
Again, remember the advice from *Effective Java* on *minimizing mutability*. Such "data classes" have the
following characteristics:
* they are (deeply) *immutable*, so have just one possible state, and are therefore quite easy to reason about
* they tend to use the type-safe `java.util.Optional` rather than `null` to describe optional data fields
* they even tend to "attract" the now de-facto standard [JSpecify annotations](https://jspecify.dev/) to help keep `null` away as much as possible
* they "attract" the immutable Guava collections such as `ImmutableList` and `ImmutableSet`, in order to explicitly promise immutability
  * note that these immutable Guava collections are "regular" *Java collections*, with stronger immutability guarantees than "unmodifiable collections"
* they do *not use any proxies*, so what you see is what you get, and there is *no hidden state*
* related to the previous bullet point: they typically contain *no annotations* and therefore *do not depend on any annotation processing* external to the data class
* they are *thread-safe* (if all of their record components are immutable as well)
* they are technology-agnostic, just like the abstract service layer Java interfaces passing them around
* they do not support "bidirectional associations" if they are deeply immutable
  * that is, record object trees are purely hierarchical ("top-down") data structures, just like XML and JSON trees
  * this is consistent with their immutable nature; one constructor call creates the (potentially deeply nested) record, which cannot be updated in-place afterward
* in practice, they tend to "attract" modern Java APIs (that use immutable data structures), such as `java.time.Instant`
  * just compare `java.util.Date` and `java.util.Calendar` on the one hand with the *Java time API* on the other hand; it's no contest, really
* out of the box, they offer natural *value equality* (through provided overridden `equals` and `hashCode` methods)
* this programming style is rooted in modern *functional Java programming*, characterized by "immutability preferred, and side effects minimized/localized"
  * there is a clear influence from OO/FP languages like *Scala*, which showed that OO is not about mutability, and that OO and FP go well together
  * limiting mutability and side effects tends to help improve code quality (again compare Java's legacy "date-time" API versus the later one)

Maybe this is not a big deal in a small code base, but in a large code base this makes a big difference
in maintainability and low bug counts.

Let's put this another way. Suppose we are maintaining a large and complex code base, in which there are
deep call chains of transactional services calling transactional services (typically all working in the
context of the same transaction, if the transaction propagation is "REQUIRED"). So the transactional
Hibernate `Session`/`EntityManager` is kept open across many service method calls in the call stack.

Now suppose that deep in such a call stack data is *read from a (non-trivial) JPA entity*. What don't we
know about that JPA entity at that point in the code, unless we consider the calling context? Some questions
that arise are the following ones:
* are we inside a transactional Hibernate `Session`/`EntityManager`, so is there an open *persistence context*?
* if so, what is the "lifecycle status" of the entity? is it *managed*, *transient*, *detached* or *removed*?
* if the (managed) entity has been retrieved at the beginning of the `Session`, what updates have since been made to the entity?
* are specific fields of non-primitive types `null` or are they filled?
* to what extent have *associations* been loaded (and do we currently have a persistence context, or do we potentially invite a `LazyInitialisationException`)?
* related, which (association) fields are *proxy objects*?

These are questions we can only answer when looking at the context of the code (higher up in the call chain).
That is, we *cannot locally reason about the JPA entities*, so we make it easier to introduce bugs. Also,
the Java compiler cannot help us here, which is a pity because Java's compile-time type-safety is a core
strength of Java, making up for Java's verbosity.

Next suppose that deep in that call stack data is *updated in the JPA entity* (possibly via "chains" of
associations as the left-hand side of the assignment). Due to Hibernate's *dirty checking*, it is quite
possible that higher up in the call chain, just before the `Session` is closed and the transaction is
committed, the updates to the managed JPA entity/entities are flushed to the database. In other words,
we *cannot locally reason about database updates*.

Contrast this with the use of *immutable Java records* as "data carriers", and *explicit* database query
and update calls. All the issues above disappear. There is *no hidden state*. There are *no hidden database
updates*. As a bonus, we get thread-safety as well, which is needed in case the Java records are used in
multiple threads. Updates become "functional updates", with Java records that are copies of the original
except for some "changes". Admittedly, typically more code would be needed than when working exclusively with
JPA entities as data carriers, but the code is simple and clear, and *locally reasoning about code* is
largely restored.

This is especially true if (even many `private`) methods have *immutable parameters and return values* (without
using `void` as return type), using *as little hidden (program) state as required*, and having *as few
side effects as required*. In other words, functions that are *closer to pure functions* in *functional
programming*, thus enabling *local reasoning* about code.

Yet where do we convert JPA entities to immutable Java records? One possibility is to do that within the
open `EntityManager`. We could turn "result sets" directly into Java records, or we could convert
JPA entities into Java records while still in an open `EntityManager`. The latter comes with some overhead
of unnecessarily filling the first-level cache, but it can make conversion from JPA entity trees to
Java records easy, if we have some custom (`private`) methods turning JPA entities (of which we know
to what extent associations have been fetched) into immutable Java records.

I have tried out the latter approach several times now, also in this project, and it works well, in my
opinion. A gotcha may be that I did not always see this work well when calling method `TypedQuery.getResultStream`.
When calling `TypedQuery.getResultList`, and then converting the JPA entity result `List` into a
collection of Java records (through a "Java Stream pipeline"), I haven't seen any data loss so far.

To avoid first-level cache overhead when using JPA entities only as very short-lived data structures
that are immediately converted to immutable Java records within the open `Session`/`EntityManager`,
consider using Hibernate's [`StatelessSession`](https://thorben-janssen.com/hibernates-statelesssession/).
Do consider the consequences, though (apart from using a "non-standard" API, if that's considered a problem).
For example, Hibernate then no longer guarantees that *reading the same entity multiple times within the
same `Session` returns the same Java object*. Code that inserts or updates entities is also more verbose,
there is no cascading support, and the code is closer to JDBC/SQL. This could be a good thing, though.

Hibernate's `StatelessSession` is probably vastly underused, to a large extent due to its absence from
the JPA standard. Gavin King even calls this
[his billion-dollar mistake](https://in.relation.to/2025/09/24/a-billion-dollar-mistake/). The good
thing is that we can almost pretend it is there in JPA, because even when using `StatelessSession`
Criteria queries can be written as JPA Criteria queries (depending only on JPA), etc. So in practice
code using `StatelessSession` may well look much the same as JPA code, with only a few Hibernate-specific
import statements. Of course the main difference with `Session`/`EntityManager` is its stateless nature.

In summary, in my opinion a *service layer* in a large Java code base using Hibernate looks like this at the
boundary:
* *Java interfaces* for the abstract service layer API contracts
* the abstract methods in these Java interfaces take and return *immutable data*, such as *immutable Java records*
  * to help enforce immutability of these Java records, *Guava immutable collections* are a good fit for collection-valued fields
* service implementation internals are completely hidden behind these API contracts
  * these internals directly or indirectly (via "repositories") either depend on Hibernate's `Session`/`EntityManager` or on Hibernate's `StatelessSession` (or on jOOQ)

Making this service layer contract quite visible also helps in enforcing "proper" application layering.
That is, service layer methods return "data objects", but these data objects themselves do not (directly
or indirectly) call service layer methods. This way it becomes more clear where the performance costs are,
where transactional boundaries are, etc.

One last note about these immutable model classes:
* they should depend on nothing else in the code base
  * that is, JPA entities depend on immutable model classes for conversions from JPA to immutable model
  * but not the other way around; the model knows nothing about JPA
* often we want to expose model data as JSON, XML etc.
  * consider introducing separate classes for those concerns
  * recall the *single responsibility* principle in *SOLID*
  * for example, a JPA entity is a *Java representation of a database table row*, no more, no less
  * and a JAXB-annotated class is a *Java representation of XML data*, etc.
  * mixing these concerns in the same data class quickly becomes a mess
* it is also perfectly ok to offer specific "views" on non-trivial Java records as nested record classes
  * e.g., such "views" could leave out some "associations"
  * using explicit types makes this explicit, whereas this is implicit in JPA entities

## Using jOOQ where JPA/Hibernate offers less value

Sometimes we don't want the runtime overhead of creating many managed JPA entities in the "persistence
context" during JPQL/Criteria query execution. Admittedly, using a Hibernate `StatelessSession` we can
avoid these runtime costs, if we are fine with losing features like lazy loading, dirty checking and
cascading. Yet occasionally we might want to use more advanced SQL features (possibly database-specific)
than supported by Hibernate. In such cases, in a Spring context, we used to work with plain SQL and the
Spring `JdbcTemplate`. This approach does have some limitations, such as:
* manually composing SQL strings, without good support for reuse of query parts (in particular where only the "where" clause differs)
* boilerplate code to turn sets of result set rows into nested object graphs
* lacking light-weight abstractions over differences between database-specific SQL dialects

This is where [jOOQ](https://www.jooq.org/) comes in as an excellent companion/alternative to Hibernate.

Do keep in mind, though, that for commercial database products there are license costs involved when using jOOQ.
This should not be a problem for larger organisations, and it helps the jOOQ team improve and expand
their product line, but it's important to be aware of this. So, for PostgreSQL and MySQL jOOQ is free of
charge, whereas for Oracle and Db2 it is not.

That said, gone are the days that SQL `select` statements only return flat data rows, where result set
conversion to nested Java object graphs requires a lot of boilerplate code. First of all, *SQL/JSON*
is now ubiquitous, so returning result sets with *nested collections* is already possible, and this
makes direct conversions from result set rows to Java object graphs possible. Yet jOOQ goes further
than that, and makes *nested collection processing* practical through its support for
[multisets](https://blog.jooq.org/jooq-3-15s-new-multiset-operator-will-change-how-you-think-about-sql/)
and [row expressions](https://www.jooq.org/doc/latest/manual/sql-building/column-expressions/row-value-expressions/).
For database products that natively offer multiset and row value expressions, jOOQ leverages that support.
Otherwise, jOOQ bases its support for these SQL expressions on the database's SQL/JSON support.

Also see [No more `MultipleBagFetchException`](https://blog.jooq.org/no-more-multiplebagfetchexception-thanks-to-multiset-nested-collections/)
for an advantage of jOOQ over Hibernate when it comes to processing multiple nested collections in the
same query.

Like JPA/Hibernate with its support for type-safe metamodel and Criteria queries, jOOQ can generate a
type-safe Java representation of the database's data model. The latter directly represents the DDL SQL.
Type-safe SQL querying/updates is also supported by jOOQ, and by all means, we should use it.
The type-safe SQL DSL in jOOQ reads like SQL, but is type-checked by the Java compiler. In that sense
it is similar to type-safe Criteria queries in JPA, using the metamodel instead of strings for attribute
names etc. Yet jOOQ's queries are SQL queries, not "entity queries". The completeness of jOOQ's support
for SQL is quite impressive, so this is a big plus of jOOQ in those cases where JPA/Hibernate does not
support SQL features we want to use.

In a Spring Boot application, support for jOOQ is on par with its support for JPA. Transaction management
is left to Spring, and instead of an injected `EntityManager` we would use an injected jOOQ
`DSLContext`.

My (somewhat limited) experiences with jOOQ used in this way are quite positive. Note that type-safety
is lost if a "tuple" has more than 22 columns, but on the other hand, we can always introduce row value
expressions to mitigate this limitation. Reuse of type-safe SQL "query parts" is also supported, if we
do that in the recommended way (depending only on jOOQ types such as `org.jooq.Table` and `org.jooq.Condition`).

In principle there is no reason why using `EntityManager`, `StatelessSession` and `DSLContext` in the
same code base would be a problem. Note that this goes well together with technology-agnostic service
API contracts, with methods that take and return immutable data values.

## Addendum: learning from best practices regarding the use of the Java `Stream` API

Above the case was made for limiting/encapsulating mutability and side effects when using Hibernate.
Another motivation for this can be found in best practices around the use of the `java.util.stream.Stream`
API, where similar advice is given for functions at a finer granularity.

Consider the
[`java.util.stream` package summary](https://docs.oracle.com/en/java/javase/25/docs/api/java.base/java/util/stream/package-summary.html).

This package summary speaks of *behavioral parameters* of *Stream operations*. These are the "functions"
passed as parameters to "higher-order functions" such as `Stream.map` and `Stream.filter`. These parameters
are instances of *functional interfaces*, such as `java.util.function.Function` (typically passed as
lambda expressions or method references).

The package summary makes the case for these behavioral parameters to be as close to *pure deterministic
functions* as possible. That is:
* they must be *non-interfering*
* they should typically be *stateless*
* they should typically have *no side effects*
* not mentioned there, but still important: they should typically be *total functions*

### Non-interference

Not only should a "behavioral parameter" be non-interfering, but other code should not interfere
with the (non-concurrent) data source of a running *stream pipeline* either. A contrived example of (highly
undesirable) *interference* with the (non-concurrent) data source could be like this:

```java
int n = 30_000_000;

// The data source (a mutable non-thread-safe List), so it can be interfered with
List<Integer> source = new ArrayList<>(IntStream.range(0, n).boxed().toList());

// Interference with the data source (see below, where this Runnable is used)
Runnable interference = () -> IntStream.range(0, n).forEach(i -> source.set(i, -source.get(i)));

Runnable runnable = () -> {
    // Using the data source, which is being interfered with, in a Stream pipeline
    List<Integer> triples = source.stream().map(n -> 3 * n).toList();

    boolean resultIsCorrect = triples.equals(IntStream.range(0, n).mapToObj(n -> 3 * n).toList());
    System.out.printf("Result collection is correct: %b%n", resultIsCorrect); // Expecting false, due to the interference
    // The elements that probably were not interfered with
    System.out.printf("Number of non-negative numbers: %d%n", triples.stream().filter(n -> n >= 0).count());
    // The elements that were interfered with
    System.out.printf("Number of negative numbers (due to interference): %d%n", triples.stream().filter(n -> n < 0).count());
};

CompletableFuture<Void> future = CompletableFuture.allOf(
    CompletableFuture.runAsync(interference, CompletableFuture.delayedExecutor(10, TimeUnit.MILLISECONDS)),
    CompletableFuture.runAsync(runnable)
);

future.get();
```

Note that in this case the behavioral function `n -> 3 * n` did not interfere with the data source
itself. This behavioral function is as "pure" and *deterministic* as a function can be (except for potential
integer overflow, for large values of `n`). It is other code interfering with the data source during execution
of the stream pipeline.

Had we used a Guava `ImmutableList` as data source, non-interference with the data source would have
been ensured right from the start. That would be non-interference taken to the max. Typically, that is
not needed, if the data source does not escape the current thread, but this sharp contrast helps understand
the concept of non-interference in the context of `Stream` pipelines. Of course, concurrent collections
as stream pipeline data sources would help achieve non-interference as well.

Non-interference is to a large extent about *thread-safety*. Non-synchronized access to *shared mutable state*
(so mutable state shared by threads) clearly invites data corruption. Mitigation strategies easily follow
from this:
* *do not share* data across threads
  * i.e., keep data *local to the current thread*
  * this is the most widely used strategy to prevent thread-safety issues
  * this approach scales very well
* *do not mutate* data
  * i.e., work with *immutable data*, such as immutable Java records
  * such data can easily be shared across threads without any issues
  * this approach scales quite well, especially for read-only data requiring no (functional) updates
  * I have successfully used this approach for a shared deeply immutable XBRL taxonomy model (wrapping thousands of immutable XML DOM trees)
* *synchronize access to shared mutable data*
  * i.e., use low level or higher level synchronization mechanisms (preferably the latter)
  * low level: `synchronized`, `volatile`, even `final`; see the *Java Memory Model* for the semantics
  * high level: concurrency utilities in the `java.util.concurrent` namespace
  * note that this is not just about preventing simultaneous access to the same data, but also about *memory visibility*
  * this approach scales poorly when using low level locking; again, use higher level APIs

Applying this to the example above, preventing interference with a data source of a running stream pipeline:
* *do not share*: any Java collection implementation (whether thread-safe or not) will do, provided:
  * it does not escape the current thread, and:
  * the stream pipeline runs in the same thread (this can be a dangerous assumption)
* *do not mutate*: immutable Guava collections are immutable and thread-safe, so cannot be tampered with
* *synchronize access to shared mutable data*: concurrent Java collection implementations will do
  * they are designed for concurrent access; note that they are "smarter" than old school synchronized collections
  * so the word "synchronize" should be considered in a broader sense than locking with the `synchronized` keyword

Of course, we can take this concept of non-interference further than just the context of stream pipelines.

For example, according to
[Hibernate advice from the Hibernate team](https://docs.hibernate.org/orm/7.1/introduction/html_single/#advice)
a "persistence context" should never be leaked across threads or concurrent transactions. In other words,
*do not share* the persistence context. Ok, but what about the injected `EntityManager` then? Clearly it
is shared by multiple threads using the same JPA functionality. The injected `EntityManager` is a Spring
proxy, though (i.e. a Spring `EntityManagerProxy`), which is itself not the target `EntityManager` bound
to one "persistence context".

Note that modern higher level concurrency APIs (including `CompletionStage` and `Stream.parallel`) make it
quite easy to create multithreaded code, so it is easy to leak a persistence context to other threads if
we are not careful. This advice from the Hibernate team is therefore important advice that should be taken
seriously.

As another (broader) example of non-interference, proper database transaction management (and in particular
transaction isolation) in code using JPA or jOOQ is also about non-interference. In Spring (Boot) applications
we typically use Spring's transaction management support (mostly by using the `@Transactional` annotation),
yet it remains the responsibility of the application programmer to use it wisely.

### Stateless

As described in the above-mentioned package summary of the `Stream` API, stateful behavioral parameters
depend on state that may change during execution of the stream pipeline. Here is another example:

```java
import java.time.Instant;

List<Integer> numbers = IntStream.range(0, 1_000_000).boxed().toList();

// Not deterministic
List<Instant> wrongInstants = numbers.stream().map(n -> Instant.now().plusMillis(n)).toList();

// Fixing the non-determinism, by making the behavioral parameter stateless
final Instant now = Instant.now();
List<Instant> fixedInstants = numbers.stream().map(now::plusMillis).toList();

Instant lastInstant = fixedInstants.getLast();
Instant expectedLastInstant = fixedInstants.getFirst().plusMillis(1_000_000 - 1);
// Prints true
System.out.println(lastInstant.equals(expectedLastInstant));
```

Again, we can take this principle of stateless behavior further, which we did when giving the advice
to use immutable Java records as DTOs rather than highly mutable JPA entities at service layer boundaries.
What is a best practice in the small may especially be a good practice in a larger context.

### No side effects

The Stream API package summary has a very clear example of undesirable and even completely unnecessary
side effects in a behavioral parameter in a stream pipeline.

A slight variation on the example given is as follows:

```java
// Unnecessary use of side effects
List<Integer> triplesIfWeAreLucky = new ArrayList<>();

// The use of "higher-order function" forEach is a give-away of side effects
// Moreover, this is not thread-safe and is therefore not going to work
// Potentially this leads to an ArrayIndexOutOfBoundsException, or to an empty result collection
IntStream.range(0, 1_000_000).parallel().boxed()
    .filter(n -> n % 3 == 0)
    .forEach(triplesIfWeAreLucky::add);
```

The obvious fix is getting rid of the unnecessary side effect:

```java
List<Integer> triples = IntStream.range(0, 1_000_000).parallel().boxed()
    .filter(n -> n % 3 == 0)
    .toList();
```

Again, we can and should take this further than just the context of stream pipelines. As discussed above,
using a `StatelessSession` rather than a `Session` (and therefore a first level cache etc.) can make a
huge difference in the number of side effects. The same goes for the use of immutable Java record DTOs
instead of JPA entities at service layer boundaries.

What I am saying here is nothing new, of course. It is also consistent with advice given in the excellent
book *Effective Java, 3rd Edition* by *Joshua Bloch*. That is a book that has stood the test of time, and is
applicable to more languages than just Java. To a large extent, that book is about writing *clear and
predictable code*. One of the 90 items in the book that stands out in the context of this article is
*minimizing mutability*. That is consistent with *localizing and minimizing side effects*, which is what
this article is largely about, in the context of Hibernate.

### Using total functions

Note that the Java stream API tends to use *total functions*, which is a good thing, limiting the number
of thrown exceptions. Take for example method `IntStream.max`. It returns an `OptionalInt`, thus accounting
for the fact that empty integer streams have no max element.

In the large, using total functions wherever this is practical is also a good practice.

## Closing remarks

As discussed above, using Hibernate (especially when using `Session` instead of `StatelessSession`) is
something of a *balancing act*. On the one hand, the *mutability of JPA entities* is great, in a small scope
where the database is accessed. On the other hand, it is a liability in a larger scope, where immutable
DTOs are more predictable data holders.

Some strongly related *guiding principles* when developing database manipulation code in Java are:
* Improve the extent to which we can *locally reason about code*
  * Clearly we can learn from *functional programming* here, as shown above in more than one way
  * We can learn quite a lot from the book *Effective Java, 3rd Edition* by Joshua Bloch as well
* Be *explicit about design intent*, preferably in a way that can be checked by the compiler and the *Java type system*
* Increase the extent to which *the Java compiler helps avoid bugs*
  * As an obvious example, prefer `Optional` to `null` (just like modern Java APIs do)
  * Note that the now de-facto "nullability checks" annotations from "jspecify.org" clearly nudge the developer towards less use of `null`

These are related principles that are more widely applicable than just when writing Java database access code;
they are even more widely applicable than in the context of Java. Yet they are particularly important when
writing Java code using Hibernate/JPA, because of the need to make a decision about the "scope of JPA entities".

Hence, one (somewhat imprecise) quality metric for such Java code could be: to what extent does the Java
compiler help to safely maintain and refactor the code?
